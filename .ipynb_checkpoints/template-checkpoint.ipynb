{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c8899e7",
   "metadata": {},
   "source": [
    "# Training a PyTorch Model\n",
    "\n",
    "This tutorial shows how to train a Logistic Regression model in PyTorch using the Census API's `experimental.ml.ExperimentDataPipe` class. This is intended only to demonstrate the use of the `ExperimentDataPipe`, and not as an example of how to train a biologically useful model.\n",
    "\n",
    "This tutorial assumes a basic familiarity with PyTorch and the Census API. See the [Querying and fetching the single-cell data and cell/gene metadata](https://chanzuckerberg.github.io/cellxgene-census/notebooks/api_demo/census_query_extract.html) notebook tutorial for a quick primer on Census API usage.\n",
    "\n",
    "**Contents**\n",
    "\n",
    "* [Open the Census](#Open-the-Census)\n",
    "* [Create a DataLoader](#Create-a-DataLoader)\n",
    "* [Define the model](#Define-the-model)\n",
    "* [Train the model](#Train-the-model)\n",
    "* [Make predictions with the model](#Make-predictions-with-the-model)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f874fb88",
   "metadata": {},
   "source": [
    "## Open the Census\n",
    "\n",
    "First, obtain a handle to the Census data, in the usual manner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3dd549f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T18:20:21.600206Z",
     "start_time": "2023-10-09T18:20:19.390343Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The \"stable\" release is currently 2024-07-01. Specify 'census_version=\"2024-07-01\"' in future calls to open_soma() to ensure data consistency.\n"
     ]
    }
   ],
   "source": [
    "import cellxgene_census\n",
    "\n",
    "census = cellxgene_census.open_soma()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "580b29f2",
   "metadata": {},
   "source": [
    "## Create an ExperimentDataPipe\n",
    "\n",
    "To train a model in PyTorch using this `census` data object, first instantiate an `ExperimentDataPipe` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54896e6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T18:20:22.278894Z",
     "start_time": "2023-10-09T18:20:21.830683Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/cellxgene-census/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cellxgene_census.experimental.ml as census_ml\n",
    "import tiledbsoma as soma\n",
    "\n",
    "experiment = census[\"census_data\"][\"homo_sapiens\"]\n",
    "\n",
    "experiment_datapipe = census_ml.ExperimentDataPipe(\n",
    "    experiment,\n",
    "    measurement_name=\"RNA\",\n",
    "    X_name=\"raw\",\n",
    "    obs_query=soma.AxisQuery(value_filter=\"tissue_general == 'tongue' and is_primary_data == True\"),\n",
    "    obs_column_names=[\"cell_type\"],\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    soma_chunk_size=10_000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04eb7742",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### `ExperimentDataPipe` class explained\n",
    "\n",
    "This class provides an implementation of PyTorch's [DataPipe interface](https://pytorch.org/data/main/torchdata.datapipes.iter.html), which defines a common mechanism for wrapping and accessing training data from any underlying source. The `ExperimentDataPipe` class encapsulates the details of querying and retrieving Census data from a single SOMA `Experiment` and returning it to the caller as PyTorch Tensors. Most importantly, it retrieves the data lazily from the Census in batches, avoiding having to load the entire training dataset into memory at once. (Note: PyTorch also provides `DataSet` as a legacy interface for wrapping and accessing training data sources, but a `DataPipe` can be used interchangeably.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44188ba8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### `ExperimentDataPipe` parameters explained\n",
    "\n",
    "The constructor only requires a single parameter, `experiment`, which is a `soma.Experiment` containing the data of the organism to be used for training.\n",
    "\n",
    "To retrieve a subset of the Experiment's data, along either the `obs` or `var` axes, you may specify query filters via the `obs_query` and `var_query` parameters, which are both `soma.AxisQuery` objects.\n",
    "\n",
    "The values for the prediction label(s) that you intend to use for training are specified via the `obs_column_names` array.\n",
    "\n",
    "The `batch_size` allows you to specify the number of obs rows (cells) to be returned by each return PyTorch tensor. You may exclude this parameter if you want single rows (`batch_size=1`).\n",
    "\n",
    "The `shuffle` flag allows you to randomize the ordering of the training data for each training epoch. Note:\n",
    "* You should use this flag instead of the `DataLoader` `shuffle` flag, as `DataLoader` does not support shuffling when used with an `IterDataPipe` dataset.\n",
    "* PyTorch's TorchData library provides a [Shuffler](https://pytorch.org/data/main/generated/torchdata.datapipes.iter.Shuffler.html) `DataPipe`, which is alternate mechanism one can use to perform shuffling of an `IterDataPipe`. However, the `Shuffler` will not \"globally\" randomize the training data, as it only \"locally\" randomizes the ordering of the training data within fixed-size \"windows\". Due to the layout of Census data, a given \"window\" of Census data may be highly homogeneous in terms of its `obs` axis attribute values, and so this shuffling strategy may not provide sufficient randomization for certain types of models.\n",
    "\n",
    "The `soma_chunk_size` sets the number of rows of data that are retrieved from the Census and held in memory at a given time. This controls\n",
    " the maximum memory usage of the `ExperimentDataPipe`. Smaller values will require less memory but will also result in lower read performance. If you are running out of memory when training a model, try reducing this value. The default is set to retrieve ~1GB of data per chunk, which takes into account how many `var` (gene) columns are being requested. This parameter also affects the granularity of the \"global\" shuffling step when `shuffle=True` (see ``shuffle`` parameter API docs for details)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84ac17d2",
   "metadata": {},
   "source": [
    "You can inspect the shape of the full dataset, without causing the full dataset to be loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70a2ddbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T18:20:32.049618Z",
     "start_time": "2023-10-09T18:20:22.821101Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15020, 60530)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_datapipe.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5251109a",
   "metadata": {},
   "source": [
    "## Split the dataset\n",
    "\n",
    "You may split the overall dataset into the typical training, validation, and test sets by using the PyTorch [RandomSplitter](https://pytorch.org/data/main/generated/torchdata.datapipes.iter.RandomSplitter.html#torchdata.datapipes.iter.RandomSplitter) `DataPipe`. Using PyTorch's functional form for chaining `DataPipe`s, this is done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "133f594f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T18:20:32.052795Z",
     "start_time": "2023-10-09T18:20:32.051289Z"
    }
   },
   "outputs": [],
   "source": [
    "train_datapipe, test_datapipe = experiment_datapipe.random_split(weights={\"train\": 0.8, \"test\": 0.2}, seed=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a825bccf",
   "metadata": {},
   "source": [
    "## Create the DataLoader\n",
    "\n",
    "With the full set of DataPipe operations chained together, we can now instantiate a PyTorch [DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) on the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39d30df2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T18:20:32.056886Z",
     "start_time": "2023-10-09T18:20:32.052898Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment_dataloader = census_ml.experiment_dataloader(train_datapipe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a3cbe3f",
   "metadata": {},
   "source": [
    "Alternately, you can instantiate a `DataLoader` object directly via its constructor. However, many of the parameters are not usable with iterable-style DataPipes, which is the case for `ExperimentDataPipe`. In particular, the `shuffle`, `batch_size`, `sampler`, `batch_sampler`, `collate_fn` parameters should not be specified. Using `experiment_dataloader` helps enforce correct usage."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb9e93b6",
   "metadata": {},
   "source": [
    "## Define the model\n",
    "\n",
    "With the training data retrieval code now in place, we can move on to defining a simple logistic regression model, using PyTorch's `torch.nn.Linear` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b792b4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T18:20:32.060262Z",
     "start_time": "2023-10-09T18:20:32.058875Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()  # noqa: UP008\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = torch.sigmoid(self.linear(x))\n",
    "        return outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e1752ef",
   "metadata": {},
   "source": [
    "Next, we define a function to train the model for a single epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b744cd21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T18:20:32.310829Z",
     "start_time": "2023-10-09T18:20:32.307661Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, train_dataloader, loss_fn, optimizer, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        X_batch, y_batch = batch\n",
    "\n",
    "        X_batch = X_batch.float().to(device)\n",
    "\n",
    "        # Perform prediction\n",
    "        outputs = model(X_batch)\n",
    "\n",
    "        # Determine the predicted label\n",
    "        probabilities = torch.nn.functional.softmax(outputs, 1)\n",
    "        predictions = torch.argmax(probabilities, axis=1)\n",
    "\n",
    "        # Compute the loss and perform back propagation\n",
    "\n",
    "        y_batch = y_batch.flatten()\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        train_correct += (predictions == y_batch).sum().item()\n",
    "        train_total += len(predictions)\n",
    "\n",
    "        loss = loss_fn(outputs, y_batch.long())\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= train_total\n",
    "    train_accuracy = train_correct / train_total\n",
    "    return train_loss, train_accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0a9fd7e",
   "metadata": {},
   "source": [
    "Note the line, `X_batch, y_batch = batch`. Since the `train_dataloader` was configured with `batch_size=16`, these variables will hold tensors of rank 2. The `X_batch` tensor will appear, for example, as:\n",
    "\n",
    "```\n",
    "tensor([[0., 0., 0.,  ..., 1., 0., 0.],\n",
    "        [0., 0., 2.,  ..., 0., 3., 0.],\n",
    "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
    "        ...,\n",
    "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
    "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
    "        [0., 0., 0.,  ..., 0., 0., 8.]])\n",
    "      \n",
    "```\n",
    "\n",
    "For `batch_size=1`, the tensors will be of rank 1. The `X_batch` tensor will appear, for example, as:\n",
    "\n",
    "```\n",
    "tensor([0., 0., 0.,  ..., 1., 0., 0.])\n",
    "```\n",
    "    \n",
    "For `y_batch`, this will contain the user-specified `obs` `cell_type` training labels. By default, these are encoded using a LabelEncoder and it will be a matrix where each column represents the encoded values of each column specified in `obs_column_names` when creating the datapipe (in this case, only the cell type). It will look like this:\n",
    "\n",
    "```\n",
    "tensor([1, 1, 3, ..., 2, 1, 4])\n",
    "\n",
    "```\n",
    "Note that cell type values are integer-encoded values, which can be decoded using `experiment_datapipe.obs_encoders` (more on this below).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "79f8b731",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "Finally, we are ready to train the model. Here we instantiate the model, a loss function, and an optimization method and then iterate through the desired number of training epochs. Note how the `train_dataloader` is passed into `train_epoch`, where for each epoch it will provide a new iterator through the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "733ec2fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T18:29:31.028253Z",
     "start_time": "2023-10-09T18:20:32.311816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.0164523 Accuracy 0.3699\n",
      "Epoch 2: Train Loss: 0.0145778 Accuracy 0.4928\n",
      "Epoch 3: Train Loss: 0.0142274 Accuracy 0.4965\n",
      "Epoch 4: Train Loss: 0.0140366 Accuracy 0.5423\n",
      "Epoch 5: Train Loss: 0.0139020 Accuracy 0.6057\n",
      "Epoch 6: Train Loss: 0.0137726 Accuracy 0.7272\n",
      "Epoch 7: Train Loss: 0.0136123 Accuracy 0.8630\n",
      "Epoch 8: Train Loss: 0.0134781 Accuracy 0.9024\n",
      "Epoch 9: Train Loss: 0.0133959 Accuracy 0.9071\n",
      "Epoch 10: Train Loss: 0.0133454 Accuracy 0.9126\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# The size of the input dimension is the number of genes\n",
    "input_dim = experiment_datapipe.shape[1]\n",
    "\n",
    "# The size of the output dimension is the number of distinct cell_type values\n",
    "cell_type_encoder = experiment_datapipe.obs_encoders[\"cell_type\"]\n",
    "output_dim = len(cell_type_encoder.classes_)\n",
    "\n",
    "model = LogisticRegression(input_dim, output_dim).to(device)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-05)\n",
    "\n",
    "for epoch in range(10):\n",
    "    train_loss, train_accuracy = train_epoch(model, experiment_dataloader, loss_fn, optimizer, device)\n",
    "    print(f\"Epoch {epoch + 1}: Train Loss: {train_loss:.7f} Accuracy {train_accuracy:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e0ffb48",
   "metadata": {},
   "source": [
    "## Make predictions with the model\n",
    "\n",
    "To make predictions with the model, we first create a new `DataLoader` using the `test_datapipe`, which provides the \"test\" split of the original dataset. For this example, we will only make predictions on a single batch of data from the test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3e33edc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T18:29:59.425527Z",
     "start_time": "2023-10-09T18:29:31.705548Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment_dataloader = census_ml.experiment_dataloader(test_datapipe)\n",
    "X_batch, y_batch = next(iter(experiment_dataloader))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19fabd54",
   "metadata": {},
   "source": [
    "Next, we invoke the model on the `X_batch` input data and extract the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00e12182",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T18:29:59.438079Z",
     "start_time": "2023-10-09T18:29:59.429107Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8,  1,  1,  8,  7,  7,  1,  8,  1,  8,  5,  1,  7,  1,  1,  1,  1,  7,\n",
       "         1,  7,  1,  1,  1,  1,  1,  7,  6,  8,  1,  1,  8,  8,  5,  5,  1,  1,\n",
       "         8,  7,  1,  7,  1,  1,  1,  1,  7,  1,  8,  5,  8,  1,  1,  1,  8,  2,\n",
       "         8,  1,  1,  7,  7,  1,  1,  1,  7,  1,  7,  7,  5,  7,  1,  5,  5,  7,\n",
       "         8,  1,  1,  1, 11,  5,  1,  1,  1,  8,  1,  1,  7,  7,  1,  7,  8,  1,\n",
       "         1,  5,  1,  1,  5,  1,  8,  5,  5,  1,  1,  7,  7,  7,  5,  1,  7,  7,\n",
       "         1,  7,  5,  7,  1,  8,  1,  5,  7,  1,  1,  1,  1,  5,  8,  5,  1,  1,\n",
       "         1,  7])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "model.to(device)\n",
    "outputs = model(X_batch.to(device))\n",
    "\n",
    "probabilities = torch.nn.functional.softmax(outputs, 1)\n",
    "predictions = torch.argmax(probabilities, axis=1)\n",
    "\n",
    "display(predictions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7cb88a5f",
   "metadata": {},
   "source": [
    "The predictions are returned as the encoded values of `cell_type` label. To recover the original cell type labels as strings, we decode using the encoders from `experiment_datapipe.obs_encoders`.\n",
    "\n",
    "At inference time, if the model inputs are not obtained via an `ExperimentDataPipe`, one could pickle the encoder at training time and save it along with the model. Then, at inference time it can be unpickled and used as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cfff865",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T18:29:59.441907Z",
     "start_time": "2023-10-09T18:29:59.439561Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['leukocyte', 'basal cell', 'basal cell', 'leukocyte',\n",
       "       'keratinocyte', 'keratinocyte', 'basal cell', 'leukocyte',\n",
       "       'basal cell', 'leukocyte', 'epithelial cell', 'basal cell',\n",
       "       'keratinocyte', 'basal cell', 'basal cell', 'basal cell',\n",
       "       'basal cell', 'keratinocyte', 'basal cell', 'keratinocyte',\n",
       "       'basal cell', 'basal cell', 'basal cell', 'basal cell',\n",
       "       'basal cell', 'keratinocyte', 'fibroblast', 'leukocyte',\n",
       "       'basal cell', 'basal cell', 'leukocyte', 'leukocyte',\n",
       "       'epithelial cell', 'epithelial cell', 'basal cell', 'basal cell',\n",
       "       'leukocyte', 'keratinocyte', 'basal cell', 'keratinocyte',\n",
       "       'basal cell', 'basal cell', 'basal cell', 'basal cell',\n",
       "       'keratinocyte', 'basal cell', 'leukocyte', 'epithelial cell',\n",
       "       'leukocyte', 'basal cell', 'basal cell', 'basal cell', 'leukocyte',\n",
       "       'capillary endothelial cell', 'leukocyte', 'basal cell',\n",
       "       'basal cell', 'keratinocyte', 'keratinocyte', 'basal cell',\n",
       "       'basal cell', 'basal cell', 'keratinocyte', 'basal cell',\n",
       "       'keratinocyte', 'keratinocyte', 'epithelial cell', 'keratinocyte',\n",
       "       'basal cell', 'epithelial cell', 'epithelial cell', 'keratinocyte',\n",
       "       'leukocyte', 'basal cell', 'basal cell', 'basal cell',\n",
       "       'vein endothelial cell', 'epithelial cell', 'basal cell',\n",
       "       'basal cell', 'basal cell', 'leukocyte', 'basal cell',\n",
       "       'basal cell', 'keratinocyte', 'keratinocyte', 'basal cell',\n",
       "       'keratinocyte', 'leukocyte', 'basal cell', 'basal cell',\n",
       "       'epithelial cell', 'basal cell', 'basal cell', 'epithelial cell',\n",
       "       'basal cell', 'leukocyte', 'epithelial cell', 'epithelial cell',\n",
       "       'basal cell', 'basal cell', 'keratinocyte', 'keratinocyte',\n",
       "       'keratinocyte', 'epithelial cell', 'basal cell', 'keratinocyte',\n",
       "       'keratinocyte', 'basal cell', 'keratinocyte', 'epithelial cell',\n",
       "       'keratinocyte', 'basal cell', 'leukocyte', 'basal cell',\n",
       "       'epithelial cell', 'keratinocyte', 'basal cell', 'basal cell',\n",
       "       'basal cell', 'basal cell', 'epithelial cell', 'leukocyte',\n",
       "       'epithelial cell', 'basal cell', 'basal cell', 'basal cell',\n",
       "       'keratinocyte'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cell_type_encoder = experiment_datapipe.obs_encoders[\"cell_type\"]\n",
    "\n",
    "predicted_cell_types = cell_type_encoder.inverse_transform(predictions.cpu())\n",
    "\n",
    "display(predicted_cell_types)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16010d09",
   "metadata": {},
   "source": [
    "Finally, we create a Pandas DataFrame to examine the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4ac8087",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T18:29:59.471320Z",
     "start_time": "2023-10-09T18:29:59.443175Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual cell type</th>\n",
       "      <th>predicted cell type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>leukocyte</td>\n",
       "      <td>leukocyte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>leukocyte</td>\n",
       "      <td>basal cell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>keratinocyte</td>\n",
       "      <td>basal cell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leukocyte</td>\n",
       "      <td>leukocyte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>keratinocyte</td>\n",
       "      <td>keratinocyte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>epithelial cell</td>\n",
       "      <td>epithelial cell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>basal cell</td>\n",
       "      <td>basal cell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>basal cell</td>\n",
       "      <td>basal cell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>basal cell</td>\n",
       "      <td>basal cell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>keratinocyte</td>\n",
       "      <td>keratinocyte</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    actual cell type predicted cell type\n",
       "0          leukocyte           leukocyte\n",
       "1          leukocyte          basal cell\n",
       "2       keratinocyte          basal cell\n",
       "3          leukocyte           leukocyte\n",
       "4       keratinocyte        keratinocyte\n",
       "..               ...                 ...\n",
       "123  epithelial cell     epithelial cell\n",
       "124       basal cell          basal cell\n",
       "125       basal cell          basal cell\n",
       "126       basal cell          basal cell\n",
       "127     keratinocyte        keratinocyte\n",
       "\n",
       "[128 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "display(\n",
    "    pd.DataFrame(\n",
    "        {\n",
    "            \"actual cell type\": cell_type_encoder.inverse_transform(y_batch.ravel().numpy()),\n",
    "            \"predicted cell type\": predicted_cell_types,\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7cd499-2ce4-4ca1-96a8-d1db7cd9e8fd",
   "metadata": {},
   "source": [
    "# Similarity Search (NEW!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefec385-fccf-485b-8cc5-9fb2906aa834",
   "metadata": {},
   "source": [
    "### Find the most similar Census cells in any other data with embeddings vector search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67caae45-0147-4ac7-942b-002a4705fba4",
   "metadata": {},
   "source": [
    "This tutorial demonstrates the experimental API in the Python `cellxgene_census` package to search Census embeddings using [TileDB-Vector-Search](https://github.com/TileDB-Inc/TileDB-Vector-Search) indexes. We will generate [scVI embeddings](https://docs.scvi-tools.org/en/1.0.0/tutorials/notebooks/api_overview.html) for some test cells, search the Census scVI embeddings for nearest neighbors, and use them to predict cell type and tissue of the test cells.\n",
    "\n",
    "To reproduce this notebook, `pip install 'cellxgene_census[experimental]' scvi-tools` and obtain the [pbmc3k blood cells data](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html) and scVI model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21171fa-ef77-40e7-b411-f09429e88eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data\n",
    "!wget --no-check-certificate -q -O data/pbmc3k_filtered_gene_bc_matrices.tar.gz http://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz\n",
    "!tar -xzf data/pbmc3k_filtered_gene_bc_matrices.tar.gz -C data/\n",
    "\n",
    "!mkdir -p scvi-human-2024-02-12\n",
    "!wget --no-check-certificate -q -O scvi-human-2024-02-12/model.pt https://cellxgene-contrib-public.s3.us-west-2.amazonaws.com/models/scvi/2024-02-12/homo_sapiens/model.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ab246e-277a-45df-bba2-4bad612226af",
   "metadata": {},
   "source": [
    "### Contents\n",
    "\n",
    "1. Loading and embedding pbmc3k cells.\n",
    "\n",
    "2. Search for similar Census cells.\n",
    "\n",
    "3. Predicting cell metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09651f79-f66d-415e-9214-5a7b245fe71c",
   "metadata": {},
   "source": [
    "⚠️ Note that the Census RNA data includes duplicate cells present across multiple datasets. Duplicate cells can be filtered in or out using the cell metadata variable `is_primary_data` which is described in the [Census schema](https://github.com/chanzuckerberg/cellxgene-census/blob/main/docs/cellxgene_census_schema.md#repeated-data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1db2411-10b0-49dd-9fc6-68895fa2d83c",
   "metadata": {},
   "source": [
    "## Loading and embedding pbmc3k cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c160970f-503a-4c83-93a0-27bb9929f52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import anndata\n",
    "import cellxgene_census\n",
    "import cellxgene_census.experimental\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scvi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f6cbfb-6fd4-4a57-a8eb-73d3725b126c",
   "metadata": {},
   "source": [
    "Load the pmbc3k cell data into an AnnData:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f9536b-4dc1-4311-98f4-0439f822114b",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_10x_mtx(\"data/filtered_gene_bc_matrices/hg19/\", var_names=\"gene_ids\")\n",
    "adata.var[\"ensembl_id\"] = adata.var.index\n",
    "adata.obs[\"n_counts\"] = adata.X.sum(axis=1)\n",
    "adata.obs[\"joinid\"] = list(range(adata.n_obs))\n",
    "adata.obs[\"batch\"] = \"unassigned\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6751330-e5d8-426e-8164-5f93bb285f49",
   "metadata": {},
   "source": [
    "Run them through the scVI forward pass and extract their latent representation (embedding):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfdaa23-47b9-46c6-b549-021caa1997f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scvi.model.SCVI.prepare_query_anndata(adata, \"scvi-human-2024-02-12\")\n",
    "vae_q = scvi.model.SCVI.load_query_data(\n",
    "    adata,\n",
    "    \"scvi-human-2024-02-12\",\n",
    ")\n",
    "\n",
    "# This allows for a simple forward pass\n",
    "vae_q.is_trained = True\n",
    "latent = vae_q.get_latent_representation()\n",
    "adata.obsm[\"scvi\"] = latent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a8e518-9514-4011-b678-4eedde99120a",
   "metadata": {},
   "source": [
    "The scVI embedding vectors for each cell are now stored in the `scvi` obsm layer. Lastly, clean up the AnnData a little:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5375b0e9-16d0-425d-985b-48643a75c67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out missing features\n",
    "adata = adata[:, adata.var[\"gene_symbols\"].notnull().values].copy()\n",
    "adata.var.set_index(\"gene_symbols\", inplace=True)\n",
    "# assign placeholder cell_type and tissue_general labels\n",
    "adata.var_names = adata.var[\"ensembl_id\"]\n",
    "adata.obs[\"cell_type\"] = \"Query - PBMC 10X\"\n",
    "adata.obs[\"tissue_general\"] = \"Query - PBMC 10X\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb86e9d-354b-4dd4-9be7-19212bb77319",
   "metadata": {},
   "source": [
    "And for visualization, compute leiden clusters on the scVI embeddings. These will come at handy later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08614511-16af-4b2c-964f-5a9ca9f1c3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(adata, n_neighbors=15, use_rep=\"scvi\")\n",
    "sc.tl.umap(adata)\n",
    "sc.tl.leiden(adata)\n",
    "sc.pl.umap(adata, color=\"leiden\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6e1b94-de1c-4b9b-8a5e-066c07c074f8",
   "metadata": {},
   "source": [
    "## Search for similar Census cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d62076-c207-437d-9412-45d5ed8de8b1",
   "metadata": {},
   "source": [
    "Use the CELLxGENE Census experimental API to search the vector index of scVI embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1856774e-7444-4ff3-806c-a25d007b4a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "CENSUS_VERSION = \"2023-12-15\"\n",
    "neighbors = cellxgene_census.experimental.find_nearest_obs(\n",
    "    \"scvi\", \"homo_sapiens\", CENSUS_VERSION, query=adata, k=30, memory_GiB=8, nprobe=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464b5687-b6f2-4665-ac11-086ffee68eb8",
   "metadata": {},
   "source": [
    "This accessed the cell embeddings in the `scvi` obsm layer and searched the latent space for the k nearest neighbors (by Euclidean distance) among the Census cell embeddings, returning the distances and obs `soma_joinids` (k for each query cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff86143-d377-4165-9c77-bd9982011221",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fe1364-18fa-4ba1-b8f3-185099ba717a",
   "metadata": {},
   "source": [
    "To explore these results, fetch an AnnData with each query cell’s (single) nearest neighbor in scVI’s latent space, including their embedding vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fef5a8f-a55d-4d72-a0ad-28a21aa124ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with cellxgene_census.open_soma(census_version=CENSUS_VERSION) as census:\n",
    "    neighbors_adata = cellxgene_census.get_anndata(\n",
    "        census,\n",
    "        \"homo_sapiens\",\n",
    "        \"RNA\",\n",
    "        obs_coords=sorted(neighbors.neighbor_ids[:, 0].tolist()),\n",
    "        obs_embeddings=[\"scvi\"],\n",
    "        X_name=\"normalized\",\n",
    "        column_names={\"obs\": [\"soma_joinid\", \"tissue\", \"tissue_general\", \"cell_type\"]},\n",
    "    )\n",
    "neighbors_adata.var_names = neighbors_adata.var[\"feature_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1749bcc0-9677-439b-8bf5-fb282dc3d8c0",
   "metadata": {},
   "source": [
    "Make a UMAP visualization of these nearest neighbors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44eae995-c40e-4996-9e40-89f35d82a22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(neighbors_adata, n_neighbors=15, use_rep=\"scvi\")\n",
    "sc.tl.umap(neighbors_adata)\n",
    "sc.pl.umap(neighbors_adata, color=\"tissue_general\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab61a1e-9c52-4068-88b9-e01b64033cd0",
   "metadata": {},
   "source": [
    "As expected, the nearest neighbors are largely Census blood cells, with some distinct cell type clusters.\n",
    "\n",
    "Now display the pbmc3k query cells together with their Census nearest neighbors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b921f63-f586-4eb3-bcca-df505fc8e838",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_concat = anndata.concat([adata, neighbors_adata])\n",
    "sc.pp.neighbors(adata_concat, n_neighbors=15, use_rep=\"scvi\")\n",
    "sc.tl.umap(adata_concat)\n",
    "sc.pl.umap(adata_concat, color=[\"tissue_general\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2535477e-bb9e-4a02-8400-e1567ec4f6d9",
   "metadata": {},
   "source": [
    "The neighbor clusters appear to correspond to cell type heterogeneity also present in the query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ee9279-0d4a-4f40-98c9-e9af46f3f980",
   "metadata": {},
   "source": [
    "## Predicting cell metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193784fb-7cd1-4edb-8bd6-051d99d7514a",
   "metadata": {},
   "source": [
    "The experimental API also has a method to predict metadata attributes of the query cells, like `tissue_general` and `cell_type`, based on the Census nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6b37ac-df35-4b51-a011-f47bb0966e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cellxgene_census.experimental.predict_obs_metadata(\n",
    "    \"homo_sapiens\", CENSUS_VERSION, neighbors, [\"tissue_general\", \"cell_type\"]\n",
    ")\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1722d673-880e-4a84-87e7-4d690be5cb8d",
   "metadata": {},
   "source": [
    "Unlike the above visualizations of single nearest neighbors, these predictions are informed by each query cell’s k=30 neighbors, with an attached confidence score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ea9c0b-5d8c-4b79-bb74-4992d1d1d08c",
   "metadata": {},
   "source": [
    "These predictions can be added to the original AnnData object for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51c0bb8-12e4-4fbb-a9db-4f27db4640ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.index = adata.obs.index\n",
    "predictions = predictions.rename(columns={\"cell_type\": \"predicted_cell_type\"})\n",
    "adata.obs = pd.concat([adata.obs, predictions], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b14d373-c2cf-4f44-8fcc-d70737a4aa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adata, color=\"predicted_cell_type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2186030e-484e-46a3-a108-7bae376ef3be",
   "metadata": {},
   "source": [
    "Now the leiden clusters calculated at the beginning can be annotated by popular vote, whereby each cluster gets assigned the most common predicted cell type from the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5c1c91-8eba-48b2-9bfe-578cc707a0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs[\"predicted_consolidated_cell_type\"] = \"\"\n",
    "for leiden_cluster in adata.obs[\"leiden\"].drop_duplicates():\n",
    "    most_popular_type = (\n",
    "        adata.obs.loc[adata.obs[\"leiden\"] == leiden_cluster,].value_counts(\"predicted_cell_type\").index[0]\n",
    "    )\n",
    "    adata.obs.loc[adata.obs[\"leiden\"] == leiden_cluster, \"predicted_consolidated_cell_type\"] = most_popular_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c561f6e-4f36-450b-b6e7-5112073a51ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adata, color=\"predicted_consolidated_cell_type\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
